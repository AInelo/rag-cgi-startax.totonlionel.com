# üé≠ Impl√©mentation des Personnalit√©s du Chatbot RAG CGI

Ce document explique l'impl√©mentation technique des trois personnalit√©s du chatbot RAG CGI.

## üèóÔ∏è Architecture

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    Interface Web/API                        ‚îÇ
‚îÇ  (s√©lection personnalit√© + question)                       ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                      ‚îÇ
                      ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    Service RAG                              ‚îÇ
‚îÇ  (recherche sources + g√©n√©ration r√©ponse)                  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                      ‚îÇ
                      ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                Service de Personnalit√©s                     ‚îÇ
‚îÇ  (g√©n√©ration prompts syst√®me personnalis√©s)                ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                      ‚îÇ
                      ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                Service LLM Gemini                          ‚îÇ
‚îÇ  (g√©n√©ration r√©ponse avec prompt personnalis√©)             ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

## üìÅ Structure des Fichiers

```
app/
‚îú‚îÄ‚îÄ services/
‚îÇ   ‚îú‚îÄ‚îÄ personnalite_service.py      # Service principal des personnalit√©s
‚îÇ   ‚îú‚îÄ‚îÄ rag_service.py               # Service RAG modifi√© pour personnalit√©s
‚îÇ   ‚îî‚îÄ‚îÄ llm_service_gemini.py       # Service LLM modifi√© pour personnalit√©s
‚îú‚îÄ‚îÄ config/
‚îÇ   ‚îî‚îÄ‚îÄ personnalite_config.py      # Configuration des param√®tres
‚îî‚îÄ‚îÄ models/
    ‚îî‚îÄ‚îÄ schemas.py                   # Mod√®les avec champ personnalite

tests/
‚îú‚îÄ‚îÄ test_personnalites.py            # Tests des personnalit√©s
‚îú‚îÄ‚îÄ test_config.py                   # Tests de configuration
‚îî‚îÄ‚îÄ demo_personnalites.py            # D√©monstration

docs/
‚îî‚îÄ‚îÄ PERSONNALITES.md                 # Documentation utilisateur
```

## üîß Composants Techniques

### 1. Service de Personnalit√©s (`personnalite_service.py`)

**Responsabilit√©s :**
- Gestion des trois personnalit√©s (Expert, Expert CGI, Math√©maticien)
- G√©n√©ration des prompts syst√®me personnalis√©s
- Interface unifi√©e pour r√©cup√©rer les prompts

**Classes principales :**
```python
class PersonnaliteType(Enum):
    EXPERT = "expert"
    EXPERT_CGI = "expert_cgi"
    MATHEMATICIEN = "mathematicien"

class PersonnaliteService:
    def get_prompt_system(self, personnalite: str) -> str
    def get_personnalite_info(self) -> Dict[str, str]
```

### 2. Configuration des Personnalit√©s (`personnalite_config.py`)

**Responsabilit√©s :**
- Param√®tres de g√©n√©ration par personnalit√©
- Support des variables d'environnement
- Validation automatique des configurations

**Configuration par d√©faut :**
```python
DEFAULT_CONFIG = {
    "expert": {
        "temperature": 0.1,        # R√©ponses d√©terministes
        "max_tokens": 150,         # R√©ponses courtes
        "top_p": 0.9,
        "top_k": 40
    },
    "expert_cgi": {
        "temperature": 0.3,        # √âquilibr√©
        "max_tokens": 1000,        # R√©ponses d√©taill√©es
        "top_p": 0.95,
        "top_k": 64
    },
    "mathematicien": {
        "temperature": 0.2,        # Pr√©cision math√©matique
        "max_tokens": 800,         # R√©ponses techniques
        "top_p": 0.92,
        "top_k": 50
    }
}
```

### 3. Int√©gration LLM (`llm_service_gemini.py`)

**Modifications apport√©es :**
- Param√®tre `personnalite` ajout√© aux m√©thodes de g√©n√©ration
- Int√©gration du service de personnalit√©s dans `_build_cgi_prompt`
- Support des prompts syst√®me personnalis√©s

**Signature modifi√©e :**
```python
def _build_cgi_prompt(self, 
                     user_query: str,
                     context_documents: Optional[List[Dict]] = None,
                     conversation_history: Optional[List[Dict]] = None,
                     system_prompt: Optional[str] = None,
                     personnalite: str = "expert_cgi") -> str:
```

### 4. Service RAG (`rag_service.py`)

**Modifications apport√©es :**
- Param√®tre `personnalite` ajout√© √† `generate_response_stream`
- Transmission de la personnalit√© au service LLM
- Support des configurations personnalis√©es

**Signature modifi√©e :**
```python
async def generate_response_stream(self, 
                                 question: str, 
                                 sources: List[DocumentSource],
                                 temperature: float = 0.3,
                                 max_tokens: int = 1000,
                                 personnalite: str = "expert_cgi") -> AsyncGenerator[Dict[str, Any], None]:
```

### 5. API FastAPI (`main.py`)

**Modifications apport√©es :**
- Champ `personnalite` ajout√© au mod√®le `QueryRequest`
- Endpoint `/personnalites` pour lister les personnalit√©s disponibles
- Transmission de la personnalit√© dans les endpoints `/query` et `/query/stream`
- Interface web avec s√©lecteur de personnalit√©

**Nouveaux endpoints :**
```python
@app.get("/personnalites")
async def get_personnalites()

@app.post("/query")
async def query_cgi(request: QueryRequest)

@app.get("/query/stream")
async def stream_query(..., personnalite: str = Query("expert_cgi"))
```

## üéØ Personnalit√©s Impl√©ment√©es

### üß† Expert
- **Objectif** : R√©ponses courtes et directes
- **Contraintes** : 2-3 phrases maximum
- **Style** : Factuel et professionnel
- **Cas d'usage** : Consultations rapides, questions simples

### üèõÔ∏è Expert CGI
- **Objectif** : R√©ponses d√©taill√©es avec r√©f√©rences
- **Contraintes** : Explications compl√®tes et structur√©es
- **Style** : Acad√©mique et professionnel
- **Cas d'usage** : √âtude approfondie, formation, conseils d√©taill√©s

### üßÆ Math√©maticien
- **Objectif** : Formules math√©matiques et calculs
- **Contraintes** : Notations KaTeX, exemples num√©riques
- **Style** : Technique et math√©matique
- **Cas d'usage** : Calculs fiscaux, formules, analyse quantitative

## üöÄ Utilisation

### Via l'API REST

```bash
# Requ√™te avec personnalit√© Expert
curl -X POST http://localhost:8080/query \
  -H "Content-Type: application/json" \
  -d '{
    "question": "Quel est le taux de TVA ?",
    "personnalite": "expert",
    "context_type": "fiscal",
    "max_sources": 3
  }'

# Requ√™te avec personnalit√© Math√©maticien
curl -X POST http://localhost:8080/query \
  -H "Content-Type: application/json" \
  -d '{
    "question": "Calculez la TVA sur 500 000 FCFA",
    "personnalite": "mathematicien",
    "context_type": "fiscal",
    "max_sources": 5
  }'
```

### Via l'Interface Web

1. Ouvrir http://localhost:8080
2. S√©lectionner la personnalit√© dans le menu d√©roulant
3. Saisir la question
4. La r√©ponse sera g√©n√©r√©e selon la personnalit√© choisie

### Via le Streaming SSE

```bash
curl -N "http://localhost:8080/query/stream?question=Quel%20est%20le%20taux%20de%20TVA&personnalite=expert"
```

## ‚öôÔ∏è Configuration

### Variables d'environnement

```bash
# Personnalit√© par d√©faut
DEFAULT_PERSONNALITE=expert_cgi

# Temp√©ratures personnalis√©es
EXPERT_TEMPERATURE=0.1
EXPERT_CGI_TEMPERATURE=0.3
MATHEMATICIEN_TEMPERATURE=0.2

# Max tokens personnalis√©s
EXPERT_MAX_TOKENS=150
EXPERT_CGI_MAX_TOKENS=1000
MATHEMATICIEN_MAX_TOKENS=800
```

### Fichier de configuration

```python
# app/config/personnalite_config.py
DEFAULT_CONFIG = {
    "expert": {
        "temperature": 0.1,
        "max_tokens": 150,
        "top_p": 0.9,
        "top_k": 40
    }
    # ... autres personnalit√©s
}
```

## üß™ Tests

### Tests des personnalit√©s

```bash
# Test complet des personnalit√©s
python3 test_personnalites.py

# Test de la configuration
python3 test_config.py

# D√©monstration
python3 demo_personnalites.py
```

### Tests dans Docker

```bash
# Copier les tests dans le container
docker cp test_personnalites.py rag-cgi-api:/app/

# Ex√©cuter les tests
docker exec -it rag-cgi-api python3 /app/test_personnalites.py
```

## üîç Monitoring et Logs

### Endpoints de monitoring

```bash
# Informations sur les personnalit√©s
curl http://localhost:8080/personnalites

# Statistiques du service
curl http://localhost:8080/stats

# Health check
curl http://localhost:8080/health
```

### Logs

```bash
# Suivre les logs en temps r√©el
docker-compose logs -f rag-cgi-api

# Logs sp√©cifiques aux personnalit√©s
docker logs rag-cgi-api | grep -i personnalite
```

## üé® Personnalisation

### Ajouter une nouvelle personnalit√©

1. **Modifier l'enum `PersonnaliteType`**
```python
class PersonnaliteType(Enum):
    EXPERT = "expert"
    EXPERT_CGI = "expert_cgi"
    MATHEMATICIEN = "mathematicien"
    NOUVELLE = "nouvelle"  # Ajouter ici
```

2. **Ajouter la m√©thode de prompt**
```python
def _get_nouvelle_prompt(self) -> str:
    return """Votre prompt personnalis√© ici..."""
```

3. **Mettre √† jour le dictionnaire**
```python
self.personnalites = {
    PersonnaliteType.EXPERT: self._get_expert_prompt(),
    PersonnaliteType.EXPERT_CGI: self._get_expert_cgi_prompt(),
    PersonnaliteType.MATHEMATICIEN: self._get_mathematicien_prompt(),
    PersonnaliteType.NOUVELLE: self._get_nouvelle_prompt()  # Ajouter ici
}
```

4. **Ajouter la configuration**
```python
DEFAULT_CONFIG = {
    "expert": {...},
    "expert_cgi": {...},
    "mathematicien": {...},
    "nouvelle": {  # Ajouter ici
        "temperature": 0.4,
        "max_tokens": 600,
        "top_p": 0.93,
        "top_k": 55
    }
}
```

5. **Tester**
```bash
python3 test_personnalites.py
```

### Modifier les prompts existants

√âditer directement dans `app/services/personnalite_service.py` :

```python
def _get_expert_prompt(self) -> str:
    return """Votre nouveau prompt personnalis√©..."""
```

## üêõ D√©pannage

### Probl√®mes courants

**Personnalit√© non reconnue :**
- V√©rifier l'orthographe exacte : `expert`, `expert_cgi`, `mathematicien`
- Consulter `/personnalites` pour la liste compl√®te
- V√©rifier les logs pour les erreurs

**R√©ponses incoh√©rentes :**
- V√©rifier que la personnalit√© est bien pass√©e dans la requ√™te
- Consulter la configuration dans `personnalite_config.py`
- V√©rifier les variables d'environnement

**Formules KaTeX non rendues :**
- S'assurer d'utiliser la personnalit√© "mathematicien"
- V√©rifier que le frontend supporte KaTeX
- Consulter les logs pour les erreurs de g√©n√©ration

### Commandes de diagnostic

```bash
# V√©rifier la configuration
python3 test_config.py

# Tester les personnalit√©s
python3 test_personnalites.py

# V√©rifier les endpoints
curl http://localhost:8080/personnalites
curl http://localhost:8080/health

# Logs en temps r√©el
docker-compose logs -f rag-cgi-api
```

## üìö Documentation Compl√©mentaire

- **PERSONNALITES.md** : Guide utilisateur des personnalit√©s
- **README.md** : Documentation g√©n√©rale du projet
- **API docs** : Documentation automatique FastAPI sur `/docs`

## ü§ù Contribution

1. Fork le projet
2. Cr√©ez une branche feature (`git checkout -b feature/NouvellePersonnalite`)
3. Impl√©mentez la nouvelle personnalit√©
4. Ajoutez les tests correspondants
5. Committez vos changements (`git commit -m 'Add NouvellePersonnalite'`)
6. Push vers la branche (`git push origin feature/NouvellePersonnalite`)
7. Ouvrez une Pull Request

---

**D√©velopp√© avec ‚ù§Ô∏è pour simplifier l'acc√®s au Code G√©n√©ral des Imp√¥ts du B√©nin** 