# ==============================================================================
# FILE: app/services/embedding_service.py - Service d'Embeddings Google API
# ==============================================================================

import asyncio
import logging
import numpy as np
from typing import List, Dict, Any, Optional
import json
from sklearn.metrics.pairwise import cosine_similarity
import google.generativeai as genai

logger = logging.getLogger(__name__)

class EmbeddingService:
    def __init__(self, api_key: str):
        self.api_key = api_key
        # Configuration de l'API Google
        genai.configure(api_key=api_key)
        self.embedding_model = "models/text-embedding-004"
        
    async def _make_embedding_request(self, texts: List[str]) -> List[List[float]]:
        """Fait une requ√™te √† l'API Google pour les embeddings"""
        embeddings = []
        
        try:
            for text in texts:
                # Utilisation de l'API Google pour les embeddings
                result = genai.embed_content(
                    model=self.embedding_model,
                    content=text
                )
                embedding = result["embedding"]
                embeddings.append(embedding)
                
            logger.info(f"‚úÖ {len(embeddings)} embeddings g√©n√©r√©s via Google API")
            return embeddings
            
        except Exception as e:
            logger.error(f"‚ùå Erreur lors de la requ√™te d'embedding Google: {str(e)}")
            # Fallback: embeddings al√©atoires (pour le d√©veloppement)
            return self._generate_fallback_embeddings(texts)
    
    def _generate_fallback_embeddings(self, texts: List[str]) -> List[List[float]]:
        """G√©n√®re des embeddings de fallback pour le d√©veloppement"""
        logger.warning("‚ö†Ô∏è Utilisation d'embeddings de fallback (d√©veloppement uniquement)")
        embeddings = []
        for text in texts:
            # Embedding al√©atoire de dimension 768 (comme text-embedding-004)
            embedding = np.random.normal(0, 1, 768).tolist()
            embeddings.append(embedding)
        return embeddings
    
    async def get_embeddings(self, texts: List[str]) -> List[List[float]]:
        """R√©cup√®re les embeddings pour une liste de textes"""
        if not texts:
            return []
        
        try:
            embeddings = await self._make_embedding_request(texts)
            return embeddings
        except Exception as e:
            logger.error(f"‚ùå Erreur lors de la g√©n√©ration des embeddings: {str(e)}")
            return self._generate_fallback_embeddings(texts)
    
    async def get_embedding(self, text: str) -> List[float]:
        """R√©cup√®re l'embedding pour un seul texte"""
        embeddings = await self.get_embeddings([text])
        return embeddings[0] if embeddings else []
    
    def compute_similarity(self, embedding1: List[float], embedding2: List[float]) -> float:
        """Calcule la similarit√© cosinus entre deux embeddings"""
        try:
            # Convertir en arrays numpy
            emb1 = np.array(embedding1).reshape(1, -1)
            emb2 = np.array(embedding2).reshape(1, -1)
            
            # Calculer la similarit√© cosinus
            similarity = cosine_similarity(emb1, emb2)[0][0]
            return float(similarity)
        except Exception as e:
            logger.error(f"Erreur lors du calcul de similarit√©: {str(e)}")
            return 0.0
    
    def find_most_similar(self, query_embedding: List[float], 
                              candidate_embeddings: List[List[float]], 
                          top_k: int = 5) -> List[tuple]:
        """Trouve les embeddings les plus similaires"""
        try:
            similarities = []
            for i, candidate in enumerate(candidate_embeddings):
                similarity = self.compute_similarity(query_embedding, candidate)
                similarities.append((i, similarity))
        
            # Trier par similarit√© d√©croissante
            similarities.sort(key=lambda x: x[1], reverse=True)
        
            # Retourner les top_k
            return similarities[:top_k]
        except Exception as e:
            logger.error(f"Erreur lors de la recherche de similarit√©: {str(e)}")
            return []
    
    async def cleanup(self):
        """Nettoie les ressources"""
        logger.info("üßπ Service d'embeddings Google nettoy√©")
    
    def get_model_info(self) -> Dict[str, Any]:
        """Retourne les informations sur le mod√®le d'embedding"""
        return {
            "model": self.embedding_model,
            "api_provider": "Google AI",
            "embedding_dimension": 768,
            "fallback_mode": "random_embeddings"
        }